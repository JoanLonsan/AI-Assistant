{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b50bdf93",
   "metadata": {},
   "source": [
    "# Creating AI Assistant with GPT-4o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a39ec5",
   "metadata": {},
   "source": [
    "### Before you **begin**\n",
    "\n",
    "- Make sure you have an **OpenAI developer account**.\n",
    "- Your OpenAI developer account **has credit on it**.\n",
    "- **Define an environment variable** named `OPENAI_API_KEY` containing the **API key**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4318c7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to make sure the API key is available\n",
    "import os\n",
    "\n",
    "'OPENAI_API_KEY' in os.environ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c22914",
   "metadata": {},
   "source": [
    "If the code above returns `False`, follow the steps in `openai-setup.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf5bb80",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f20a5b",
   "metadata": {},
   "source": [
    "You may need to run\n",
    "\n",
    "```%pip install openai==1.46.0```\n",
    "\n",
    "If you're using a terminal or script, just drop the %\n",
    "\n",
    "```pip install openai==1.46.0```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bee5e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import openai\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bdc283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining an OpenAI client\n",
    "client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f69d0be",
   "metadata": {},
   "source": [
    "## 1. Upload the Papers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f4df8f",
   "metadata": {},
   "source": [
    "So that GPT knows about the latest AGI research, we will provide it with some arxiv papers. There are 10 recent papers on AGI stored in the `papers` directory of this workbook.\n",
    "\n",
    "_The papers were found by searching arxiv for \"AGI\", then eyballing recent papers for content on definitions of AGI or progress towards AGI._\n",
    "\n",
    "The table below shows the filenames and the titles of the papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "142798b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>papers/2405.10313v1.pdf</td>\n",
       "      <td>How Far Are We From AGI?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>papers/2401.03428v1.pdf</td>\n",
       "      <td>EXPLORING LARGE LANGUAGE MODEL BASED INTELLIGE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>papers/2401.09395v2.pdf</td>\n",
       "      <td>CAUGHT IN THE QUICKSAND OF REASONING, FAR FROM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>papers/2401.13142v3.pdf</td>\n",
       "      <td>Unsocial Intelligence: an Investigation of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>papers/2403.02164v2.pdf</td>\n",
       "      <td>Cognition is All You Need The Next Layer of AI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>papers/2403.12107v1.pdf</td>\n",
       "      <td>Scenarios for the Transition to AGI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>papers/2404.10731v1.pdf</td>\n",
       "      <td>What is Meant by AGI? On the Definition of Art...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>papers/2312.11562v5.pdf</td>\n",
       "      <td>A Survey of Reasoning with Foundation Models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>papers/2311.02462v2.pdf</td>\n",
       "      <td>Levels of AGI: Operationalizing Progress on th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>papers/2310.15274v1.pdf</td>\n",
       "      <td>Systematic AI Approach for AGI: Addressing Ali...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  filename                                              title\n",
       "0  papers/2405.10313v1.pdf                           How Far Are We From AGI?\n",
       "1  papers/2401.03428v1.pdf  EXPLORING LARGE LANGUAGE MODEL BASED INTELLIGE...\n",
       "2  papers/2401.09395v2.pdf  CAUGHT IN THE QUICKSAND OF REASONING, FAR FROM...\n",
       "3  papers/2401.13142v3.pdf  Unsocial Intelligence: an Investigation of the...\n",
       "4  papers/2403.02164v2.pdf  Cognition is All You Need The Next Layer of AI...\n",
       "5  papers/2403.12107v1.pdf                Scenarios for the Transition to AGI\n",
       "6  papers/2404.10731v1.pdf  What is Meant by AGI? On the Definition of Art...\n",
       "7  papers/2312.11562v5.pdf       A Survey of Reasoning with Foundation Models\n",
       "8  papers/2311.02462v2.pdf  Levels of AGI: Operationalizing Progress on th...\n",
       "9  papers/2310.15274v1.pdf  Systematic AI Approach for AGI: Addressing Ali..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a DataFrame with paper titles and filenames\n",
    "papers = pd.DataFrame({\n",
    "    \"filename\": [\n",
    "        \"2405.10313v1.pdf\",\n",
    "        \"2401.03428v1.pdf\",\n",
    "        \"2401.09395v2.pdf\",\n",
    "        \"2401.13142v3.pdf\",\n",
    "        \"2403.02164v2.pdf\",\n",
    "        \"2403.12107v1.pdf\",\n",
    "        \"2404.10731v1.pdf\",\n",
    "        \"2312.11562v5.pdf\",\n",
    "        \"2311.02462v2.pdf\",\n",
    "        \"2310.15274v1.pdf\"\n",
    "    ],\n",
    "    \"title\": [\n",
    "        \"How Far Are We From AGI?\",\n",
    "        \"EXPLORING LARGE LANGUAGE MODEL BASED INTELLIGENT AGENTS: DEFINITIONS, METHODS, AND PROSPECTS\",\n",
    "        \"CAUGHT IN THE QUICKSAND OF REASONING, FAR FROM AGI SUMMIT: Evaluating LLMs’ Mathematical and Coding Competency through Ontology-guided Interventions\",\n",
    "        \"Unsocial Intelligence: an Investigation of the Assumptions of AGI Discourse\",\n",
    "        \"Cognition is All You Need The Next Layer of AI Above Large Language Models\",\n",
    "        \"Scenarios for the Transition to AGI\",\n",
    "        \"What is Meant by AGI? On the Definition of Artificial General Intelligence\",\n",
    "        \"A Survey of Reasoning with Foundation Models\",\n",
    "        \"Levels of AGI: Operationalizing Progress on the Path to AGI\",\n",
    "        \"Systematic AI Approach for AGI: Addressing Alignment, Energy, and AGI Grand Challenges\"\n",
    "    ]\n",
    "})\n",
    "# Adding the path to the filename\n",
    "papers[\"filename\"] = \"papers/\" + papers[\"filename\"]\n",
    "# Displaying the DataFrame\n",
    "papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d94ad0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to upload files to OpenAI\n",
    "def upload_file_for_assistant(file_path):\n",
    "    uploaded_file = client.files.create( # API call to upload the file\n",
    "        file = open(file_path, \"rb\"), # Opening the file in binary mode (rb = read binary)\n",
    "        purpose = 'assistants'\t# Purpose of the file upload (e.g., for assistant use). Other options include 'fine-tune' and 'search'\n",
    "    )\n",
    "    \n",
    "    return uploaded_file.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b67c664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload each file in the 'filename' column and collect their IDs\n",
    "uploaded_file_ids = papers[\"filename\"].apply(upload_file_for_assistant).to_list()\n",
    "\n",
    "# Display the uploaded file IDs\n",
    "uploaded_file_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e7b3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the files using code\n",
    "client.files.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d0f328",
   "metadata": {},
   "source": [
    "## 2. Adding the files to a Vector Store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053d6be0",
   "metadata": {},
   "source": [
    "To access the documents and get sensible results, they need to be split up into small chunks and added to a vector database.\n",
    "\n",
    "The assistants API lets you avoid worrying about the chunking stage, so you just need to specify the file IDs that you want to add to a vector database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ca74b5",
   "metadata": {},
   "source": [
    "🚨 WARNING 🚨\n",
    "<div style=\"border: 2px solid red; padding: 10px; border-radius: 5px; background-color: #ffe6e6; color: darkred;\"> ⚠️ You will get <strong>charged daily</strong> for having a vector database. By default, it is automatically deleted after 7 days of inactivity, but I <strong>strongly recommend deleting it</strong> right after this code-along if you don't want to be charged for the full week. </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9150e858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vector store to enable semantic search over the uploaded files.\n",
    "vstore = client.beta.vector_stores.create(\n",
    "    file_ids=uploaded_file_ids, # list of uploaded file IDs to include in the store\n",
    "    name=\"arxiv_agi_papers\" # custom name to help identify this vector store later\n",
    ")\n",
    "\n",
    "# Display the created vector store object\n",
    "vstore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5abe12f",
   "metadata": {},
   "source": [
    "### Check that this worked\n",
    "\n",
    "View the vector stores in your account at https://platform.openai.com/storage/vector_stores\n",
    "\n",
    "or:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24e2048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the vector stores using code\n",
    "client.beta.vector_stores.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ed9e29",
   "metadata": {},
   "source": [
    "## 3. Create the Assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1550ed7",
   "metadata": {},
   "source": [
    "The assistant needs a prompt describing how it should behave. This consists of a few paragraphs of text that give GPT information about what its role is, what it should be talking about, and how to phrase the responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ac3e7f",
   "metadata": {},
   "source": [
    "### 💡 Pro Tip: Let ChatGPT Help You Prompt Itself\n",
    "\n",
    "> 🧠 **Yes, you can use ChatGPT (or any LLM) to write prompts _for_ assistants — just like writing anything else.**  \n",
    "> In fact, the prompt below was written by ChatGPT itself and only lightly edited by a human.\n",
    "\n",
    "---\n",
    "\n",
    "#### 📝 The Meta-Prompt I Used\n",
    "\n",
    "Here’s the actual prompt I gave ChatGPT to generate the instruction for the assistant:\n",
    "\n",
    "<div style=\"border-left: 4px solid #6c63ff; padding: 1em; background-color: #f4f4ff; margin: 1em 0; border-radius: 6px; font-family: monospace; font-size: 0.95em;\">\n",
    "I'm going to make a GPT assistant that explains the contents of journal articles about artificial general intelligence.  \n",
    "The assistant, named <strong>'Aggie'</strong>, must be able to read arXiv papers in PDF form and explain the contents of those papers to an audience of data scientists.  \n",
    "Please suggest a good instruction prompt for the AI assistant.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d469ed30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 👇 This is the core prompt that defines how the assistant will behave.\n",
    "assistant_prompt = \"\"\"\n",
    "You are Aggie, a knowledgeable and articulate AI assistant specializing in artificial general intelligence (AGI). Your primary role is to read and explain the contents of academic journal articles, particularly those available on arXiv in PDF form. Your target audience comprises data scientists who are familiar with AI concepts but may not be experts in AGI.\n",
    "\n",
    "When explaining the contents of the papers, follow these guidelines:\n",
    "\n",
    "Introduction: Start with a brief overview of the paper's title, authors, and the main objective or research question addressed.\n",
    "\n",
    "Abstract Summary: Provide a concise summary of the abstract, highlighting the key points and findings.\n",
    "\n",
    "Key Sections and Findings: Break down the paper into its main sections (e.g., Introduction, Methods, Results, Discussion). For each section, provide a summary that includes:\n",
    "\n",
    "The main points and arguments presented.\n",
    "Any important methods or techniques used.\n",
    "Key results and findings.\n",
    "The significance and implications of these findings.\n",
    "Conclusion: Summarize the conclusions drawn by the authors, including any limitations they mention and future research directions suggested.\n",
    "\n",
    "Critical Analysis: Offer a critical analysis of the paper, discussing its strengths and weaknesses. Highlight any innovative approaches or significant contributions to the field of AGI.\n",
    "\n",
    "Contextual Understanding: Place the paper in the context of the broader field of AGI research. Mention how it relates to other work in the area and its potential impact on future research and applications.\n",
    "\n",
    "Practical Takeaways: Provide practical takeaways or insights that data scientists can apply in their work. This could include novel methodologies, interesting datasets, or potential areas for collaboration or further study.\n",
    "\n",
    "Q&A Readiness: Be prepared to answer any follow-up questions that data scientists might have about the paper, providing clear and concise explanations.\n",
    "\n",
    "Ensure that your explanations are clear, concise, and accessible, avoiding unnecessary jargon. Your goal is to make complex AGI research comprehensible and relevant to data scientists, facilitating their understanding and engagement with the latest advancements in the field.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1648e42",
   "metadata": {},
   "source": [
    "Now the assistant can be created. You simply give it a name, the prompt, the model to use (in this case GPT-4o), and specify which tools and resources it is allowed to use.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Define the assistant. Assign to `aggie`.\n",
    "    - Call it \"Aggie\" (or another memorable name).\n",
    "    - Give it the `assistant_prompt`.\n",
    "    - Set the model to use, `gpt-4o`.\n",
    "    - Give it access to the file search tool.\n",
    "    - Give it access to the vector store tool resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db1146b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the assistant using the OpenAI API, specifying the model and the vector store for file search.\n",
    "aggie = client.beta.assistants.create(\n",
    "    name=\"Aggie\",\n",
    "    instructions=assistant_prompt,\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[{\"type\": \"file_search\"}],\n",
    "    tool_resources={\"file_search\":{\"vector_store_ids\":[vstore.id]}}\n",
    ")\n",
    "    \n",
    "# Display the created assistant object\n",
    "aggie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1a1f53",
   "metadata": {},
   "source": [
    "### Check that this worked\n",
    "\n",
    "View the assistants in your account at https://platform.openai.com/playground/assistants\n",
    "\n",
    "or:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b4ce6e",
   "metadata": {},
   "source": [
    "# Check the assistants using code\n",
    "client.beta.assistants.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8b7df3",
   "metadata": {},
   "source": [
    "## 4. Create a Conversation Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24018930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread object. Assign to conversation.\n",
    "conversation = client.beta.threads.create()\n",
    "\n",
    "# See the result\n",
    "conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4e85fa",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "- Add a user message to the conversation. Assign to `msg_what_is_agi`.\n",
    "    - Give it the thread id.\n",
    "    - Make it a user message.\n",
    "    - Ask \"What are the most common definitions of AGI?\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055c003d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 💬 Add a user message to the conversation thread\n",
    "msg_what_is_agi = client.beta.threads.messages.create(\n",
    "    thread_id=conversation.id,\n",
    "    role=\"user\",\n",
    "    content=\"What are the most common definitions of AGI?\"\n",
    ")\n",
    "\n",
    "# Display the message object to see the response from the assistant.\n",
    "msg_what_is_agi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba933da",
   "metadata": {},
   "source": [
    "## 5. Run the assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93126a1f",
   "metadata": {},
   "source": [
    "Running the assistant requires an event handler to make it print the responses. While it's fairly tricky code, you never need to change it. This code is taken verbatim from [the OpenAI assistants documentation](https://platform.openai.com/docs/assistants/overview)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b92b728",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "- Run the code to define an event handler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30aa5068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "# Run this\n",
    "from typing_extensions import override\n",
    "from openai import AssistantEventHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7094650e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom event handler class to handle events from the assistant.\n",
    "class EventHandler(AssistantEventHandler):    \n",
    "  @override\n",
    "  def on_text_created(self, text) -> None:\n",
    "    print(f\"\\nassistant > \", end=\"\", flush=True)\n",
    "  @override\n",
    "  def on_text_delta(self, delta, snapshot):\n",
    "    print(delta.value, end=\"\", flush=True)\n",
    "      \n",
    "  def on_tool_call_created(self, tool_call):\n",
    "    print(f\"\\nassistant > {tool_call.type}\\n\", flush=True)\n",
    "  \n",
    "  def on_tool_call_delta(self, delta, snapshot):\n",
    "    if delta.type == 'code_interpreter':\n",
    "      if delta.code_interpreter.input:\n",
    "        print(delta.code_interpreter.input, end=\"\", flush=True)\n",
    "      if delta.code_interpreter.outputs:\n",
    "        print(f\"\\n\\noutput >\", flush=True)\n",
    "        for output in delta.code_interpreter.outputs:\n",
    "          if output.type == \"logs\":\n",
    "            print(f\"\\n{output.logs}\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5995f246",
   "metadata": {},
   "source": [
    "Finally, we are ready to run the assistant to get it to answer our question. The code is the same every time, so we can wrap it in a function.\n",
    "\n",
    "Streaming responses mean that text is displayed a few words at a time, rather than waiting for the entirety of the text to be generated and printing all at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f53ed905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to run the assistant in a streaming mode.\n",
    "# The assistant will respond to user messages in real-time, providing a more interactive experience.\n",
    "def run_aggie():\n",
    "    with client.beta.threads.runs.stream(\n",
    "        thread_id=conversation.id,\n",
    "        assistant_id=aggie.id,\n",
    "        event_handler=EventHandler(),\n",
    "    ) as stream:\n",
    "        stream.until_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f26826b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the assistant\n",
    "run_aggie()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba29760",
   "metadata": {},
   "source": [
    "## 6. Add another msg and Run it Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8d1e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a question to the assistant\n",
    "question = input() # The user can input a question to the assistant, which will be processed in real-time.\n",
    "# Add the user question to the conversation thread\n",
    "msg_question = client.beta.threads.messages.create(\n",
    "    thread_id=conversation.id, # The ID of the conversation thread where the message will be added\n",
    "    role=\"user\", # The role of the message sender (in this case, the user)\n",
    "    content=question # The content of the message (the user's question)\n",
    ")\n",
    "\n",
    "# Display the message object to see the response from the assistant.\n",
    "msg_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b92df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the assistant again\n",
    "run_aggie()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
